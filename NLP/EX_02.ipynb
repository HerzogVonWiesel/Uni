{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat Tweets.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete\n",
    "tweets = pd.read_csv('Tweets.csv')\n",
    "cl_tw = tweets.dropna(subset=['text','airline_sentiment'])\n",
    "cl_tw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_tw['airline_sentiment'].value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airlines = []\n",
    "sentiments = []\n",
    "\n",
    "for airline in cl_tw['airline'].unique():\n",
    "  airlines.append(airline)\n",
    "  sentiments.append(list(cl_tw[cl_tw['airline'] == airline]['airline_sentiment']))\n",
    "\n",
    "plt.hist(sentiments, label=airlines)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_tw['tweet_length'] = cl_tw['text'].str.len()\n",
    "plt.hist(cl_tw['tweet_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# from nltk.corpus import stopwords\n",
    "# stop_words = stopwords.words('english')\n",
    "\n",
    "# cl_tw['text_without_stopwords'] = cl_tw['text_lowered'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "# nltk.download('wordnet')\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# cl_tw['text_lemmatized'] = cl_tw['text_without_stopwords'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split()]))\n",
    "# cl_tw.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK 2: Pre-process the input texts, i.e., tweets, for classification. You can use external libraries like nltk for this task.\n",
    "\n",
    "Bring the texts to lower case.\n",
    "Remove stop words from the lower-cased text.\n",
    "Perform lemmatization on the lower-cased text without stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK 2: Pre-process the input texts, i.e., tweets, for classification. You can use external libraries like nltk for this task.\n",
    "\n",
    "# Bring the texts to lower case.\n",
    "# Remove stop words from the lower-cased text.\n",
    "# Perform lemmatization on the lower-cased text without stop words.\n",
    "\n",
    "# Complete\n",
    "\n",
    "cl_tw['text_lowered'] = cl_tw['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, stopwords):\n",
    "    return ' '.join([word for word in text.split() if word not in (stopwords)])\n",
    "\n",
    "\n",
    "# Complete\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "cl_tw['text_lowered_without_stopwords'] = cl_tw['text_lowered'].apply(lambda x: remove_stopwords(x, stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text, lemmatizer):\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "\n",
    "# Complete\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "cl_tw['text_lowered_without_stopwords_lemmatized'] = cl_tw['text_lowered_without_stopwords'].apply(lambda x: lemmatize(x, lemmatizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_tw.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 3:** \n",
    "1. Obtain TF-IDF features for the pre-processed input texts. You are encouraged to use the `scikit-learn` for this.\n",
    "2. Split the data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer  # hint\n",
    "\n",
    "np.random.seed(42)  # this is to make sure you get reproducable results\n",
    "\n",
    "def tf_idf(texts):\n",
    "    # Complete\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    return X.toarray(), vectorizer\n",
    "\n",
    "X, vectorizer = tf_idf(cl_tw['text_lowered_without_stopwords_lemmatized'])\n",
    "y = cl_tw['airline_sentiment']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Complete\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 4:**\n",
    "1. Train a 2-layer perceptron with one hidden layer of the size 30 on your training data. You are encouraged to use the `scikit-learn` library for this task. You can use the default hyperparameters set [here](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html).\n",
    "\n",
    "2. Test your trained MLP on the test data and report accuracy, f1_score and confusion matrix of the predictions.\n",
    "\n",
    "Food for thought: Which hyperparameter values can improve your model? Hint: Look at the guidelines at the end of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier as MLP # hint\n",
    "# Complete, one hidden layer of size 30\n",
    "clf = MLP(hidden_layer_sizes=(30), max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Complete\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1: \", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Complete\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Complete\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5:** From task 1, you might have noticed that most of the tweets start with \"@{airline_username}\", e.g., \"@VirginAmerica\". In this task, you will test if your trained model has been biased with respect to the airline name or not.\n",
    "\n",
    "1. What fraction of the tweets start with \"@{airline_username}\"?\n",
    "2. Remove \"@{airline_username}\" from all the texts that start with this pattern.\n",
    "3. Re-apply the pre-processings from TASK 2 and re-fit your TF-IDF feature on the new texts.\n",
    "4. Re-train your MLP using the TF-IDF features from step 3. Make sure to use the same train/test split.\n",
    "5. Test your new MLP and report accuracy, f1_score, confusion matrix. Are the results different from task 4? How do you interpret your observations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_airline_usernames(text, airline_usernames):\n",
    "    return ' '.join([word for word in text.split() if word not in (airline_usernames)])\n",
    "\n",
    "\n",
    "# Complete\n",
    "airline_usernames = set()\n",
    "cl_tw['text_without_airline_username'] = cl_tw['text_lowered_without_stopwords_lemmatized'].apply(lambda x: remove_airline_usernames(x, airline_usernames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete\n",
    "X, vectorizer = tf_idf(cl_tw['text_without_airline_username'])\n",
    "y = cl_tw['airline_sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complete\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#Complete\n",
    "clf = MLP(hidden_layer_sizes=(30), max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Complete\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred, average='macro'))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1: \", f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "#Complete\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#Complete\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 6**: In this task, you will analyze how your MLP features/neurons are behaving with respect to class prediction. To this end, you will examine which neurons in your MLP model have the largest weights when predicting classes.\n",
    "\n",
    "1. Using the `coefs_` attribute from your trained MLP model, plot a bar chart that shows the score of each of the 30 neurons in your model for each class. \n",
    "\n",
    "Hint: Plot the scores only for the output layer. You don't need to plot the scores for the hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **TASK 6**: In this task, you will analyze how your MLP features/neurons are behaving with respect to class prediction. To this end, you will examine which neurons in your MLP model have the largest weights when predicting classes.\n",
    "\n",
    "# 1. Using the `coefs_` attribute from your trained MLP model, plot a bar chart that shows the score of each of the 30 neurons in your model for each class. \n",
    "\n",
    "# Hint: Plot the scores only for the output layer. You don't need to plot the scores for the hidden layer.\n",
    "\n",
    "# Complete\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Complete\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "index = np.arange(30)\n",
    "bar_width = 0.35\n",
    "opacity = 0.8\n",
    "\n",
    "\n",
    "# Complete\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
